{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "122feb7a-6551-4364-a117-67469d487650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©\n",
      "âœ… Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Accuracy): 1.000\n",
      "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…Ù‚ÙŠØ§Ø³ Ø¨Ù†Ø¬Ø§Ø­\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from math import radians, cos, sin, sqrt, atan2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# Ø¯Ø§Ù„Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠØ© Ø¨ÙŠÙ† Ù†Ù‚Ø·ØªÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ø¯Ù„Ø© Haversine\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  # Ù†ØµÙ Ù‚Ø·Ø± Ø§Ù„Ø£Ø±Ø¶ Ø¨Ø§Ù„ÙƒÙŠÙ„ÙˆÙ…ØªØ±\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    return R * 2 * atan2(sqrt(a), sqrt(1 - a))  # Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨Ø§Ù„ÙƒÙŠÙ„ÙˆÙ…ØªØ±\n",
    "\n",
    "# ØªÙˆÙ„ÙŠØ¯ Ø¹ÙŠÙ†Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù…Ø­Ø§ÙƒØ§Ø© Ø­Ø§Ù„Ø© Ø·Ø§Ø¦Ø±ØªÙŠÙ†\n",
    "def generate_sample():\n",
    "    def rand_coord(): return random.uniform(20.0, 30.0)         # Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„Ø·Ø§Ø¦Ø±Ø©\n",
    "    def rand_alt(): return random.randint(3000, 12000)          # Ø§Ù„Ø§Ø±ØªÙØ§Ø¹ Ø¨Ø§Ù„Ù‚Ø¯Ù…\n",
    "    def rand_speed(): return random.randint(200, 900)           # Ø§Ù„Ø³Ø±Ø¹Ø© ÙƒÙ…/Ø³\n",
    "    def rand_heading(): return random.randint(0, 360)           # Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø¨Ø§Ù„Ø¯Ø±Ø¬Ø§Øª\n",
    "\n",
    "    # Ø§Ø®ØªÙŠØ§Ø± Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù…Ù† Ø¹Ø¯Ø© Ø­Ø§Ù„Ø§Øª ÙˆØ§Ù‚Ø¹ÙŠØ©\n",
    "    scenario = random.choice([\n",
    "        \"safe_clear\",         # Ø·Ø§Ø¦Ø±Ø§Øª Ø¨Ø¹ÙŠØ¯Ø© ÙˆØ¢Ù…Ù†Ø©\n",
    "        \"safe_altitude_gap\",  # Ù‚Ø±ÙŠØ¨Ø§Øª Ù„ÙƒÙ† ÙØ±Ù‚ Ø§Ù„Ø§Ø±ØªÙØ§Ø¹ ÙƒØ¨ÙŠØ±\n",
    "        \"conflict_close\",     # Ù‚Ø±ÙŠØ¨Ø§Øª Ø¨Ø§Ù„Ù…Ø³Ø§ÙØ© ÙˆØ§Ù„Ø§Ø±ØªÙØ§Ø¹ (Ø®Ø·Ø± ÙˆØ§Ø¶Ø­)\n",
    "        \"conflict_converge\",  # Ù…Ø³Ø§Ø±Ø§Øª Ù…ØªÙ‚Ø§Ø±Ø¨Ø© Ø¨Ø³Ø±Ø¹Ø§Øª Ù…ØªØ´Ø§Ø¨Ù‡Ø© (ØªØµØ§Ø¯Ù… Ù…Ø­ØªÙ…Ù„)\n",
    "        \"safe_opposite\",      # Ù‚Ø±ÙŠØ¨ÙŠÙ† Ù„ÙƒÙ† Ø¨Ø§ØªØ¬Ø§Ù‡ÙŠÙ† Ù…Ø®ØªÙ„ÙÙŠÙ†\n",
    "    ])\n",
    "\n",
    "    # ØªÙˆÙ„ÙŠØ¯ Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø·Ø§Ø¦Ø±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰\n",
    "    lat1 = rand_coord()\n",
    "    lon1 = rand_coord()\n",
    "    alt1 = rand_alt()\n",
    "    speed1 = rand_speed()\n",
    "    heading1 = rand_heading()\n",
    "\n",
    "    # ØªÙˆÙ„ÙŠØ¯ Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø·Ø§Ø¦Ø±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ\n",
    "    if scenario == \"safe_clear\":\n",
    "        lat2 = lat1 + random.uniform(0.05, 0.1)\n",
    "        lon2 = lon1 + random.uniform(0.05, 0.1)\n",
    "        alt2 = alt1 + random.randint(1000, 3000)\n",
    "        label = 0\n",
    "\n",
    "    elif scenario == \"safe_altitude_gap\":\n",
    "        lat2 = lat1 + random.uniform(0.001, 0.005)\n",
    "        lon2 = lon1 + random.uniform(0.001, 0.005)\n",
    "        alt2 = alt1 + random.randint(1500, 3000)\n",
    "        label = 0\n",
    "\n",
    "    elif scenario == \"conflict_close\":\n",
    "        lat2 = lat1 + random.uniform(0.0005, 0.002)\n",
    "        lon2 = lon1 + random.uniform(0.0005, 0.002)\n",
    "        alt2 = alt1 + random.randint(-200, 200)\n",
    "        label = 1\n",
    "\n",
    "    elif scenario == \"conflict_converge\":\n",
    "        lat2 = lat1 + random.uniform(0.002, 0.004)\n",
    "        lon2 = lon1 + random.uniform(0.002, 0.004)\n",
    "        alt2 = alt1 + random.randint(-300, 300)\n",
    "        heading1 = heading2 = random.randint(90, 110)  # Ù†ÙØ³ Ø§Ù„Ø§ØªØ¬Ø§Ù‡\n",
    "        speed2 = speed1 + random.randint(-20, 20)\n",
    "        label = 1\n",
    "\n",
    "    elif scenario == \"safe_opposite\":\n",
    "        lat2 = lat1 + random.uniform(0.001, 0.004)\n",
    "        lon2 = lon1 + random.uniform(0.001, 0.004)\n",
    "        alt2 = alt1 + random.randint(800, 2000)\n",
    "        heading2 = (heading1 + 180) % 360  # Ø¹ÙƒØ³ Ø§Ù„Ø§ØªØ¬Ø§Ù‡\n",
    "        speed2 = rand_speed()\n",
    "        label = 0\n",
    "\n",
    "    else:\n",
    "        lat2 = rand_coord()\n",
    "        lon2 = rand_coord()\n",
    "        alt2 = rand_alt()\n",
    "        speed2 = rand_speed()\n",
    "        heading2 = rand_heading()\n",
    "        label = 0\n",
    "\n",
    "    # ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø³Ø±Ø¹Ø© ÙˆØ§Ù„Ø§ØªØ¬Ø§Ù‡ Ù„Ù„Ø·Ø§Ø¦Ø±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© ÙÙŠ ÙƒÙ„ Ø§Ù„Ø­Ø§Ù„Ø§Øª\n",
    "    speed2 = speed2 if 'speed2' in locals() else rand_speed()\n",
    "    heading2 = heading2 if 'heading2' in locals() else rand_heading()\n",
    "\n",
    "    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø´ØªÙ‚Ø©\n",
    "    distance = haversine(lat1, lon1, lat2, lon2)\n",
    "    alt_diff = abs(alt1 - alt2)\n",
    "    speed_diff = abs(speed1 - speed2)\n",
    "    heading_diff = abs((heading1 - heading2 + 180) % 360 - 180)  # ÙØ±Ù‚ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø¨Ø¯Ù‚Ø©\n",
    "\n",
    "    return {\n",
    "        'lat1': lat1, 'lon1': lon1, 'alt1': alt1, 'speed1': speed1, 'heading1': heading1,\n",
    "        'lat2': lat2, 'lon2': lon2, 'alt2': alt2, 'speed2': speed2, 'heading2': heading2,\n",
    "        'distance': distance,\n",
    "        'alt_diff': alt_diff,\n",
    "        'speed_diff': speed_diff,\n",
    "        'heading_diff': heading_diff,\n",
    "        'label': label\n",
    "    }\n",
    "\n",
    "# ØªÙˆÙ„ÙŠØ¯ 5000 Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­ÙØ¸Ù‡Ø§\n",
    "data = [generate_sample() for _ in range(5000)]\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"conflict_dataset.csv\", index=False)\n",
    "print(\"âœ… ØªÙ… Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©\")\n",
    "\n",
    "# ===== ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ =====\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "df = pd.read_csv(\"conflict_dataset.csv\")\n",
    "\n",
    "# ÙØµÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¹Ù† Ø§Ù„Ù‡Ø¯Ù (label)\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "# ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹ÙŠØ§Ø± Ø§Ù„Ù‚ÙŠØ§Ø³ Standardization Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙŠØ²Ø§Øª\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ø®ØªØ¨Ø§Ø±\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠ Ù…Ø¹ Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Ø·Ø¨Ø§Ø¹Ø© Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"âœ… Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Accuracy): {accuracy:.3f}\")\n",
    "\n",
    "# Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…Ù‚ÙŠØ§Ø³ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ù… Ù„Ø§Ø­Ù‚Ù‹Ø§ ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©\n",
    "joblib.dump(model, \"toweriq_model_prob.pkl\")\n",
    "joblib.dump(scaler, \"toweriq_scaler_prob.pkl\")\n",
    "print(\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…Ù‚ÙŠØ§Ø³ Ø¨Ù†Ø¬Ø§Ø­\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac0ad94-ec98-495e-8efb-120e0ee51897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ  Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„ØªØµØ§Ø¯Ù…: 99.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saifw\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯Ù„ ÙˆØ§Ù„Ù…Ù‚ÙŠØ§Ø³\n",
    "model = joblib.load(\"toweriq_model_prob.pkl\")\n",
    "scaler = joblib.load(\"toweriq_scaler_prob.pkl\")\n",
    "\n",
    "# Ø¯Ø§Ù„Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠØ©\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    return R * 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "# Ù…Ø«Ø§Ù„: Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ø·Ø§Ø¦Ø±ØªÙŠÙ†\n",
    "sample = {\n",
    "    \"lat1\": 24.5,\n",
    "    \"lon1\": 46.7,\n",
    "    \"alt1\": 9000,\n",
    "    \"speed1\": 700,\n",
    "    \"heading1\": 90,\n",
    "    \"lat2\": 24.502,\n",
    "    \"lon2\": 46.702,\n",
    "    \"alt2\": 9050,\n",
    "    \"speed2\": 710,\n",
    "    \"heading2\": 95\n",
    "}\n",
    "\n",
    "# Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø´ØªÙ‚Ø©\n",
    "distance = haversine(sample[\"lat1\"], sample[\"lon1\"], sample[\"lat2\"], sample[\"lon2\"])\n",
    "alt_diff = abs(sample[\"alt1\"] - sample[\"alt2\"])\n",
    "speed_diff = abs(sample[\"speed1\"] - sample[\"speed2\"])\n",
    "heading_diff = abs((sample[\"heading1\"] - sample[\"heading2\"] + 180) % 360 - 180)\n",
    "\n",
    "# ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ù…ØµÙÙˆÙØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©\n",
    "X_input = np.array([[sample[\"lat1\"], sample[\"lon1\"], sample[\"alt1\"], sample[\"speed1\"], sample[\"heading1\"],\n",
    "                     sample[\"lat2\"], sample[\"lon2\"], sample[\"alt2\"], sample[\"speed2\"], sample[\"heading2\"],\n",
    "                     distance, alt_diff, speed_diff, heading_diff]])\n",
    "\n",
    "# Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "X_scaled = scaler.transform(X_input)\n",
    "\n",
    "# ØªÙˆÙ‚Ø¹ Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„ØªØµØ§Ø¯Ù…\n",
    "probability = model.predict_proba(X_scaled)[0][1]  # [0][1] = Ø§Ø­ØªÙ…Ø§Ù„ Ø£Ù† ÙŠÙƒÙˆÙ† \"ØªØµØ§Ø¯Ù…\"\n",
    "\n",
    "print(f\"ğŸŸ  Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„ØªØµØ§Ø¯Ù…: {probability:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1453f4-e301-4810-a9d4-169b5eb777ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
